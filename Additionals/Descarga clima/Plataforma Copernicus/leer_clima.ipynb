{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pygrib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname='Descarga clima/adaptor.mars.internal-1717268592.0452838-16207-1-fea13bf8-c9cc-4307-8feb-ae16295472d3.grib'\n",
    "gribs = pygrib.open(fname)\n",
    "# Lista para almacenar los DataFrames de cada mensaje\n",
    "df_list = []\n",
    "\n",
    "# Itera sobre los mensajes en el archivo\n",
    "for i, grb in enumerate(gribs):\n",
    "    if i >= 150000000:\n",
    "        break\n",
    "    # Extrae los datos del mensaje\n",
    "\n",
    "    if i >= 0:\n",
    "        data, lats, lons = grb.data()\n",
    "        valid_date = grb.validDate.strftime(\"%Y-%m-%d\")\n",
    "        # Crea un DataFrame para este mensaje\n",
    "        df = pd.DataFrame({\n",
    "            'latitude': lats.ravel(),\n",
    "            'longitude': lons.ravel(),\n",
    "            'value': data.ravel(),\n",
    "            'message_name': [grb.name] * len(data.ravel()),  # Agrega el nombre del mensaje\n",
    "            'valid_date': [valid_date] * len(data.ravel())  # Fecha de validez del mensaje en formato Y-m-d\n",
    "\n",
    "        })\n",
    "        \n",
    "        # Agrega el DataFrame a la lista\n",
    "        df_list.append(df)\n",
    "\n",
    "# Combina todos los DataFrames en uno solo\n",
    "df_final = pd.concat(df_list, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado Bases\\temp_1.csv\n",
      "Guardado Bases\\temp_2.csv\n",
      "Guardado Bases\\temp_3.csv\n",
      "Guardado Bases\\temp_4.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "n = 4\n",
    "\n",
    "# Obtener el número total de filas en el DataFrame\n",
    "total_rows = len(df_final)\n",
    "\n",
    "# Calcular el tamaño de cada parte\n",
    "chunk_size = total_rows // n\n",
    "\n",
    "# Crear un directorio para almacenar los archivos si no existe\n",
    "output_dir = \"Bases\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Dividir el DataFrame y guardar cada parte\n",
    "for i in range(n):\n",
    "    start_index = i * chunk_size\n",
    "    end_index = (i + 1) * chunk_size if i < n - 1 else total_rows\n",
    "    df_chunk = df_final.iloc[start_index:end_index]\n",
    "    \n",
    "    # Nombre del archivo\n",
    "    file_name = os.path.join(output_dir, f\"temp_{i + 1}.csv\")\n",
    "    \n",
    "    # Guardar el DataFrame en un archivo CSV\n",
    "    df_chunk.to_csv(file_name, index=False)\n",
    "    \n",
    "    print(f\"Guardado {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory c:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\\Tesis\n",
      "c:\\Users\\Nainh\\Proton Drive\\nainho1306 (1)\\My files\\UB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "# get current directory\n",
    "path = os.getcwd()\n",
    "print(\"Current Directory\", path)\n",
    " \n",
    "# prints parent directory\n",
    "print(os.path.abspath(os.path.join(path, os.pardir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TESIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
